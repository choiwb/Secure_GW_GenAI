
import streamlit as st
import json
import ssl
from langchain import LLMChain
from typing import Any, List, Optional
from langchain.llms.base import LLM
from langchain.callbacks.manager import CallbackManagerForLLMRun
from langchain import PromptTemplate
import httpx

# HCX í† í° ê³„ì‚°ê¸° API í˜¸ì¶œ
from hcx_token_cal import token_completion_executor


API_KEY='API KEY !!!!!!!!!!!!!!!!!!!!!!!!1'
API_KEY_PRIMARY_VAL='API KEY PRIMARY VAL !!!!!!!!!!!!!!!!!!!!!!!!1'
REQUEST_ID='REQUEST ID !!!!!!!!!!!!!!!!!!!!!'
llm_url = 'your llm url !!!!!!!!!!'



SYSTEMPROMPT = """ë‚˜ëŠ” íŠ¹ì • ì—…ì¢… ìŒì‹ì  ì‚¬ì¥ë‹˜ ì´ë‹¤.

íŠ¹ì • ì—…ì¢… ìŒì‹ì  ì— ëŒ€í•œ ì‚¬ìš©ì ë¦¬ë·°ì˜ ë‹µë³€ì„
ì‚¬ì¥ìœ¼ë¡œì„œ, ë¦¬ë·°ë¥¼ ë‹¬ë ¤ê³  í•œë‹¤.

<ì£¼ì˜ ì‚¬í•­>
1. ë¦¬ë·° ì‘ì„± ì‹œ, ì‚¬ìš©ì ì£¼ë¬¸ ë©”ë‰´ë¥¼ ê³ ë ¤í•˜ì—¬, ë³µìˆ˜ì˜ ë©”ë‰´ë¥¼ ì£¼ë¬¸í•˜ì˜€ì„ ë•Œ, 
ì‚¬ìš©ìê°€ ë¦¬ë·°ë¥¼ 1ê°€ì§€ ë©”ë‰´ ë§Œ ë‹¤ëŠ” ê²½ìš°,
ë‹¤ë¥¸ ì£¼ë¬¸í•œ ë©”ë‰´ì— ëŒ€í•œ ë°˜ë¬¸ í˜•íƒœì˜ ë‹µë³€ë„ í¬í•¨ ë˜ì–´ì•¼ í•¨.
2. ì‚¬ìš©ìì˜ ë¦¬ë·°ê°€ ê¸/ë¶€ì •ì— ë”°ë¼, ê·¸ì— ë§ëŠ” ì´ëª¨í‹°ì½˜ì„ ë‹µë³€ ë§ˆì§€ë§‰ì— ë°˜ë“œì‹œ ì‚½ì….

<ì˜ˆì‹œ>
ì‚¬ìš©ì ì£¼ë¬¸ ë©”ë‰´: ê°„ì§œì¥,í•´ë¬¼ ì§¬ë½• êµ°ë§Œë‘
ì‚¬ìš©ì ë¦¬ë·°: ê°„ì§œì¥ì´ ì •ë§ ë§›ìˆì–´ìš”.~~~~! ë‹¤ìŒë²ˆì— ë˜ ì‹œì¼œë¨¹ì„ ê³„íšì´ì—ìš”!
ì‚¬ì¥ë‹˜: ê°„ì§œì¥ì´ ì •ë§ ë§›ìˆì—ˆë‹¤ë‹ˆ ê°ì‚¬í•©ë‹ˆë‹¤. í˜¹ì‹œ, í•´ë¬¼ ì§¬ë½•ê³¼ êµ°ë§Œë‘ëŠ” ì–´ë– ì…¨ëŠ” ì§€ìš”~??^^"""

template = """ì‚¬ìš©ì ì£¼ë¬¸ ë©”ë‰´: {menu}
ì‚¬ìš©ì ë¦¬ë·°: {review}
ì‚¬ì¥ë‹˜: """
    
    
    
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context
 


class HCX_stream(LLM):
    @property
    def _llm_type(self) -> str:
        return "HyperClovaX"
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        if stop is not None:
            raise ValueError("stop kwargs are not permitted.")

        preset_text = [{"role": "system", "content": SYSTEMPROMPT}, {"role": "user", "content": prompt}]
        
        print('---------------------------------------------')
        print(preset_text)

        request_data = {
            'messages': preset_text,
            'topP': 0.8,
            'topK': 0,
            'maxTokens': 512,
            'temperature': 0.9,
            'repeatPenalty': 5.0,
            'stopBefore': [],
            'includeAiFilters': True
        }

        # def execute(self, completion_request):
        headers = {
            'X-NCP-CLOVASTUDIO-API-KEY': API_KEY,
            'X-NCP-APIGW-API-KEY': API_KEY_PRIMARY_VAL,
            'X-NCP-CLOVASTUDIO-REQUEST-ID': REQUEST_ID,
            'Content-Type': 'application/json; charset=utf-8',
            # streaming ì˜µì…˜ !!!!!
            'Accept': 'text/event-stream'
        }

        full_response = ""
        message_placeholder = st.empty()
        
        with httpx.stream(method="POST", 
                        url=llm_url,
                        json=request_data,
                        headers=headers, 
                        timeout=120) as res:
            for line in res.iter_lines():
                if line.startswith("data:"):
                    split_line = line.split("data:")
                    line_json = json.loads(split_line[1])
                    if "stopReason" in line_json and line_json["stopReason"] == None:
                        full_response += line_json["message"]["content"]
                        print('************************************************************')
                        print(full_response)
                        message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
            return full_response


hcx_llm = HCX_stream()
prompt = PromptTemplate(template=template, input_variables=["menu", "review"])

hcx_llm_chain = LLMChain(prompt=prompt, llm=hcx_llm)

# if 'generated' not in st.session_state:
#     st.session_state['generated'] = []
 
# if 'past' not in st.session_state:
#     st.session_state['past'] = []
 
# with st.form('form', clear_on_submit=True):
#     # user_input_1 = st.text_input('ì‚¬ìš©ì ì£¼ë¬¸ ë©”ë‰´', '', key='menu')
#     # user_input_2 = st.text_input('ì‚¬ìš©ì ë¦¬ë·°', '', key='review')

#     user_input_1 = st.text_input('ì‚¬ìš©ì ì£¼ë¬¸ ë©”ë‰´', default_menu, key='menu')
#     user_input_2 = st.text_input('ì‚¬ìš©ì ë¦¬ë·°', default_review, key='review')

#     submitted = st.form_submit_button('ì‚¬ì¥ë‹˜ ë‹µë³€')
 
#     if submitted and user_input_1 and user_input_2:
#         with st.spinner("Waiting for HyperCLOVA..."): 
#             response_text = hcx_llm_chain.predict(menu = user_input_1, review = user_input_2)

#             single_turn_text_json = {
#             "messages": [
#             {
#                 "role": "system",
#                 "content": template
#             },
#             {
#                 "role": "user",
#                 "content": user_input_1
#             },
#             {
#                 "role": "user",
#                 "content": user_input_2
#             },
#             {
#                 "role": "assistant",
#                 "content": response_text
#             }
#             ]
#             }
            
#             single_turn_text_token = token_completion_executor.execute(single_turn_text_json)
#             print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')
#             print(single_turn_text_json)
#             single_turn_token_count = single_turn_text_token[0]['count'] + single_turn_text_token[1]['count'] + single_turn_text_token[2]['count'] + single_turn_text_token[3]['count']
#             single_turn_token_count = sum(token['count'] for token in single_turn_text_token[:4])

#             st.session_state.past.append({'menu': user_input_1, 'review': user_input_2})
#             # st.session_state.generated.append({'generated': response_text, 'token_count': single_turn_token_count})
#             st.session_state.generated.append({'generated': response_text})
 
#         if st.session_state['generated']:
#             for i in range(len(st.session_state['generated']) - 1, -1, -1):
#                 user_input = st.session_state['past'][i]
#                 response = st.session_state['generated'][i]

#                 message(f"ì‚¬ìš©ì ì£¼ë¬¸ ë©”ë‰´: {user_input['menu']}", is_user=True, key=str(i) + '_menu')
#                 message(f"ì‚¬ìš©ì ë¦¬ë·°: {user_input['review']}", is_user=True, key=str(i) + '_review')
#                 message(f"ì‚¬ì¥ë‹˜ ë‹µë³€: {response['generated']}", is_user=False, key=str(i) + '_generated')
#                 message(f"ì´ í† í° ìˆ˜: {response['token_count']}", is_user=False, key=str(i) + '_token_count')




st.title("ìŒì‹ì  ì‚¬ì¥ë‹˜ ë¦¬ë·° ìë™ ìƒì„±")
 
default_menu = 'ì–‘ë… ì¹˜í‚¨ 1ë§ˆë¦¬, ì¹˜ì¦ˆë³¼ 5ê°œ, ì½œë¼ 1.25L'
default_review = 'ì–‘ë… ì¹˜í‚¨ì´ ì¡´ë§›íƒ±ì´ê³ , ë‹¤ë¦¬ì‚´ì´ ì •ë§ ë¶€ë“œëŸ¬ì›Œìš©~~ ê·¸ë¦¬ê³  ê°€ìŠ´ì‚´ë„ ì•ˆí½í½í•˜ê³  ì¢‹ì•„ìš”! ë˜ ì‹œì¼œë¨¹ì„ê²Œìš”!'

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'reviews' not in st.session_state:
    st.session_state.reviews = []

with st.form('review_form', clear_on_submit=True):
    # ì‚¬ìš©ì ë¦¬ë·° ë° ë³„ì  ì…ë ¥
    st.markdown("""
    <h2 style="font-size: 24px; display: inline-block; margin-right: 10px;">ğŸ§‘ ë§ˆë¼ë³´ì´ ë‹˜</h2>
    <span style="font-size: 16px; vertical-align: super;">3ì‹œê°„ ì „, ì‘ì„±ë¨.</span>
""", unsafe_allow_html=True)
    st.markdown("""
    <style>
        .rating-container {
            display: flex;
            align-items: center;
            justify-content: flex-start;
        }
        .star-rating {
            color: gold;
            font-size: 20px; /* ë³„ì˜ í¬ê¸°ë¥¼ ì¡°ì ˆí•˜ë ¤ë©´ ì´ ê°’ì„ ë³€ê²½í•˜ì„¸ìš” */
            margin-right: 5px; /* ë³„ê³¼ í…ìŠ¤íŠ¸ ì‚¬ì´ì˜ ê°„ê²©ì„ ì¡°ì ˆí•˜ë ¤ë©´ ì´ ê°’ì„ ë³€ê²½í•˜ì„¸ìš” */
        }
        .rating-label {
            font-size: 16px; /* ë¼ë²¨ í…ìŠ¤íŠ¸ì˜ í¬ê¸°ë¥¼ ì¡°ì ˆí•˜ë ¤ë©´ ì´ ê°’ì„ ë³€ê²½í•˜ì„¸ìš” */
            margin-right: 10px; /* ë¼ë²¨ê³¼ ë³„ ì‚¬ì´ì˜ ê°„ê²©ì„ ì¡°ì ˆí•˜ë ¤ë©´ ì´ ê°’ì„ ë³€ê²½í•˜ì„¸ìš” */
        }
        .rating-section {
            margin-right: 20px; /* ê° í‰ì  ì„¹ì…˜ ì‚¬ì´ì˜ ê°„ê²©ì„ ì¡°ì ˆí•˜ë ¤ë©´ ì´ ê°’ì„ ë³€ê²½í•˜ì„¸ìš” */
        }
    </style>
    <div class="rating-container">
        <div class="rating-section">
            <span class="rating-label">ë§›:</span>
            <span class="star-rating">&#9733;&#9733;&#9733;&#9733;&#9734;</span>
        </div>
        <div class="rating-section">
            <span class="rating-label">ì–‘:</span>
            <span class="star-rating">&#9733;&#9733;&#9733;&#9733;&#9733;</span>
        </div>
        <div class="rating-section">
            <span class="rating-label">ë°°ë‹¬:</span>
            <span class="star-rating">&#9733;&#9733;&#9733;&#9733;&#9734;</span>
        </div>
    </div>
""", unsafe_allow_html=True)

    user_review = st.text_area('', default_review)     
    menu_items = default_menu.split(', ')
    # menu_items ê° '#' ì•ì— ë¶™ì´ê¸°
    menu_items = ['#' + item for item in menu_items]
    st.markdown(f"""
    <div style="display: flex; flex-wrap: wrap; gap: 10px;">
        {' '.join(f'<span class="menu-item" style="font-size: 16px; padding: 8px; background-color: #f0f2f6; border-radius: 5px;">{item}</span>' for item in menu_items)}
    </div>
""", unsafe_allow_html=True)
    # <br> ì¶”ê°€
    st.markdown('<br>', unsafe_allow_html=True)
    submit_review = st.form_submit_button('ì‚¬ì¥ë‹˜ ë¦¬ë·° ë“±ë¡')
    
    if submit_review and user_review:

        # ì‚¬ì¥ë‹˜ ë¦¬ë·° ìƒì„±
        st.markdown("""
    <h2 style="font-size: 24px; display: inline-block; margin-right: 10px;">ğŸ™‹â€â™‚ï¸ ì‚¬ì¥ë‹˜</h2>
    <span style="font-size: 16px; vertical-align: super;">ì§€ê¸ˆ, ì‘ì„±ë¨.</span>
""", unsafe_allow_html=True)
        
        owner_response = hcx_llm_chain.predict(menu=default_menu, review=user_review)


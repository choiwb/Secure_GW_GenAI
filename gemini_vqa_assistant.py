
import os
from dotenv import load_dotenv
import streamlit as st
from PIL import Image
from langchain.schema import HumanMessage
from streamlit_feedback import streamlit_feedback
from langsmith import Client
from langchain.callbacks.manager import collect_runs

from config import asa_image_path, you_icon, ahn_icon
from prompt import gemini_img_sys_message
from LCEL import reset_conversation, gemini_memory, gemini_vis_pipe, gemini_vis_vectordb_txt_pipe
from streamlit_custom_func import scroll_bottom

##################################################################################
# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

os.getenv('LANGCHAIN_TRACING_V2')
os.getenv('LANGCHAIN_PROJECT')
os.getenv('LANGCHAIN_ENDPOINT')
os.getenv('LANGCHAIN_API_KEY')
##################################################################################

client = Client()

try:
    # st.set_page_config(page_icon="ğŸš€", page_title="Cloud_Assistant", layout="wide", initial_sidebar_state="collapsed")
    st.set_page_config(page_icon="ğŸš€", page_title="Cloud_Assistant", layout="wide")
except:
    st.rerun()
    
st.markdown("<h1 style='text-align: center;'>Visual Question Answering Assistant</h1>", unsafe_allow_html=True)

with st.expander('Protocol Stack'):
    st.image(asa_image_path, caption='Protocol Stack', use_column_width=True)
    
with st.sidebar:
    st.markdown("<h3 style='text-align: center;'>ì´ë¯¸ì§€ ì—…ë¡œë“œ</h3>", unsafe_allow_html=True)
    uploaded_image = st.file_uploader("ì´ë¯¸ì§€ ì„ íƒ", type=["png", "jpg", "jpeg"])

    if uploaded_image is not None:        
        # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ Image ê°ì²´ë¡œ ë³€í™˜
        image = Image.open(uploaded_image)
        
        # ì‚¬ì´ë“œë°”ì— ì´ë¯¸ì§€ í‘œì‹œ
        st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)
        
    st.markdown('<br>', unsafe_allow_html=True)
    st.markdown("<h3 style='text-align: center;'>í”¼ë“œë°± ë°©ë²•</h3>", unsafe_allow_html=True)
    feedback_option = "faces" if st.toggle(label="`2ë‹¨ê³„` â‡„ `5ë‹¨ê³„`", value=True) else "thumbs"
    st.markdown('<br>', unsafe_allow_html=True)
    st.button("ëŒ€í™” ë¦¬ì…‹", on_click=reset_conversation, use_container_width=True)
    
if "rerun_tab" not in st.session_state:
    reset_conversation()
    st.session_state.rerun_tab = "rerun_tab"
    
if 'image_data' not in st.session_state:
    st.session_state.image_data = None
    
if "ahn_messages" not in st.session_state:
    st.session_state.ahn_messages = []

for avatar_message in st.session_state.ahn_messages:
    if avatar_message["role"] == "user":
        # ì‚¬ìš©ì ë©”ì‹œì§€ì¼ ê²½ìš°, ì‚¬ìš©ì ì•„ë°”íƒ€ ì ìš©
        avatar_icon = avatar_message.get("avatar", you_icon)
        with st.chat_message(avatar_message["role"], avatar=avatar_icon):
            st.markdown("<b>You</b><br>", unsafe_allow_html=True)
            st.markdown(avatar_message["content"], unsafe_allow_html=True)
    else:
        # AI ì‘ë‹µ ë©”ì‹œì§€ì¼ ê²½ìš°, AI ì•„ë°”íƒ€ ì ìš©
        avatar_icon = avatar_message.get("avatar", ahn_icon)
        with st.chat_message(avatar_message["role"], avatar=avatar_icon):
            with st.expander('ASA'):
                st.markdown("<b>ASA</b><br>", unsafe_allow_html=True)
                st.markdown(avatar_message["content"], unsafe_allow_html=True)
                        
if prompt := st.chat_input(""):
    scroll_bottom()    
    with st.chat_message("user", avatar=you_icon):
        st.markdown("<b>You</b><br>" + prompt, unsafe_allow_html=True)
        st.session_state.ahn_messages.append({"role": "user", "content": prompt})
        
    with st.chat_message("assistant",  avatar=ahn_icon):    
        st.markdown("<b>ASA</b><br>", unsafe_allow_html=True)
        try:     
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘....."):
                with collect_runs() as cb:
                    full_response = ""
                    message_placeholder = st.empty()
                    st.session_state.image_data = uploaded_image
                                            
                    gemini_img_message = HumanMessage(
                        content=[
                            {
                            "type": "text",
                            "text": "Provide information of given image."},
                            {"type": "image_url", "image_url": image},
                        ]
                        )
                    img_context = gemini_vis_pipe.invoke([gemini_img_sys_message, gemini_img_message])
                    
                    for chunk in gemini_vis_vectordb_txt_pipe.stream({"img_context":img_context, "question":prompt}):
                        full_response += chunk
                        message_placeholder.markdown(full_response, unsafe_allow_html=True)   
                        
                    gemini_memory.save_context({"question": prompt}, {"answer": full_response})
                    st.session_state.ahn_messages.append({"role": "assistant", "content": full_response})
                                                
                    # multimodal llm ê²°ê³¼ì— ëŒ€í•œ í”¼ë“œë°±ì€ í•„ìš” ì—†ìŒ!
                    multimodal_llm_run_id = cb.traced_runs[0].id
                    # ì‚¬ìš©ì í”¼ë“œë°±ì´ í•„ìš”í•œ ì§ˆë¬¸ì— ëŒ€í•œ ê²°ê³¼ !!
                    st.session_state.run_id = cb.traced_runs[1].id
                    
        except Exception as e:
            st.error(e, icon="ğŸš¨")

if st.session_state.get("run_id"):
    run_id = st.session_state.run_id
        
    feedback = streamlit_feedback(
        feedback_type=feedback_option,  # Apply the selected feedback style
        optional_text_label="[ì„ íƒ] í”¼ë“œë°±ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.",  # Allow for additional comments
        key=f"feedback_{run_id}"
    )

    score_mappings = {
        "thumbs": {"ğŸ‘": 1, "ğŸ‘": 0},
        "faces": {"ğŸ˜€": 1, "ğŸ™‚": 0.75, "ğŸ˜": 0.5, "ğŸ™": 0.25, "ğŸ˜": 0},
    }

    scores = score_mappings[feedback_option]

    if feedback:
        score = scores.get(feedback["score"])

        if score is not None:
            feedback_type_str = f"{feedback_option} {feedback['score']}"

            feedback_record = client.create_feedback(
                run_id,
                feedback_type_str,
                score=score,
                comment=feedback.get("text")
                )
        
            st.session_state.feedback = {
                "feedback_id": str(feedback_record.id),
                "score": score,
            }
            st.toast("í”¼ë“œë°± ë“±ë¡!", icon="ğŸ“")
        else:
            st.warning("ë¶€ì ì ˆí•œ í”¼ë“œë°±.")

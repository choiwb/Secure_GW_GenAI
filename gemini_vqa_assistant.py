

import os
import streamlit as st
from PIL import Image
from streamlit_cloud_llm_bot import reset_conversation, gemini_memory, gemini_txt_pipe, gemini_vis_pipe
from langchain.schema import HumanMessage

########################################################################
you_icon = os.path.join(os.getcwd(), 'image/you_icon.png')
ahn_icon = os.path.join(os.getcwd(), 'image/ahn_icon.png')

# asa, hcx ë³„ í”„ë¡œí† ì½œ ìŠ¤íƒ ì´ë¯¸ì§€ ê²½ë¡œ
asa_image_path = os.path.join(os.getcwd(), 'image/protocol_stack.png')
########################################################################


try:
    st.set_page_config(layout="wide")
except Exception as e:
    # í˜ì´ì§€ë¥¼ ìë™ìœ¼ë¡œ ë‹¤ì‹œ ì‹¤í–‰
    st.rerun()
    
    
st.markdown("<h1 style='text-align: center;'>Visual Question Answering Assistant</h1>", unsafe_allow_html=True)

with st.expander('Protocol Stack'):
    st.image(asa_image_path, caption='Protocol Stack', use_column_width=True)

if 'image_data' not in st.session_state:
    st.session_state.image_data = None
    
if "ahn_messages" not in st.session_state:
    st.session_state.ahn_messages = []


for avatar_message in st.session_state.ahn_messages:
    if avatar_message["role"] == "user":
        # ì‚¬ìš©ì ë©”ì‹œì§€ì¼ ê²½ìš°, ì‚¬ìš©ì ì•„ë°”íƒ€ ì ìš©
        avatar_icon = avatar_message.get("avatar", you_icon)
        with st.chat_message(avatar_message["role"], avatar=avatar_icon):
            st.markdown("<b>You</b><br>" + avatar_message["content"], unsafe_allow_html=True)
    else:
        # AI ì‘ë‹µ ë©”ì‹œì§€ì¼ ê²½ìš°, AI ì•„ë°”íƒ€ ì ìš©
        avatar_icon = avatar_message.get("avatar", ahn_icon)
        with st.chat_message(avatar_message["role"], avatar=avatar_icon):
            with st.expander('ASA'):
                st.markdown("<b>ASA</b><br>" + avatar_message["content"], unsafe_allow_html=True)

        
with st.sidebar:
    st.button("ëŒ€í™” ë¦¬ì…‹", on_click=reset_conversation(), use_container_width=True)

    uploaded_image = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["png", "jpg", "jpeg"])
    if uploaded_image is not None:
        st.session_state.image_data = uploaded_image
        
        # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ Image ê°ì²´ë¡œ ë³€í™˜
        image = Image.open(uploaded_image)
        
        # ì‚¬ì´ë“œë°”ì— ì´ë¯¸ì§€ í‘œì‹œ
        st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)
    

if prompt := st.chat_input(""):
    with st.chat_message("user", avatar=you_icon):
        st.markdown("<b>You</b><br>" + prompt, unsafe_allow_html=True)
        st.session_state.ahn_messages.append({"role": "user", "content": prompt})
        
    with st.chat_message("assistant",  avatar=ahn_icon):    
        try:     
            with st.spinner("ê²€ìƒ‰ ë° ìƒì„± ì¤‘....."):
                    # uploaded_image = st.session_state.image_data
                    
                    full_response = "<b>ASA</b><br>"
                    message_placeholder = st.empty()
                    
                    if uploaded_image is None:
                        for chunk in gemini_txt_pipe.stream({"question":prompt}):
                                    print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')
                                    print(chunk)
                                    full_response += chunk
                                    message_placeholder.markdown(full_response + "â–Œ", unsafe_allow_html=True)
                        message_placeholder.markdown(full_response, unsafe_allow_html=True)   
                    else:
                        st.session_state.image_data = uploaded_image
                        image = Image.open(uploaded_image)
                        
                        img_message = HumanMessage(
                        content=[
                            {
                            "type": "text",
                            "text": "Provide information on menu and price of given image."},
                            {"type": "image_url", "image_url": image},
                        ]
                        )
                                                                   
                        for chunk in gemini_vis_pipe.stream([img_message]):
                                    print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')
                                    print(uploaded_image)
                                    print(chunk)
                                    full_response += chunk
                                    message_placeholder.markdown(full_response + "â–Œ", unsafe_allow_html=True)
                        message_placeholder.markdown(full_response, unsafe_allow_html=True)   
                        
                    full_response_for_token_cal = full_response.replace('<b>Assistant</b><br>', '').replace('<b>ASA</b><br>', '')
                    gemini_memory.save_context({"question": prompt}, {"answer": full_response_for_token_cal})

                    print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')
                    print(gemini_memory)
                    print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')

                    st.session_state.ahn_messages.append({"role": "assistant", "content": full_response_for_token_cal})
                    
        except Exception as e:
            st.error(e, icon="ğŸš¨")

